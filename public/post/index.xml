<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Evangeline M Reynolds</title>
    <link>/post/</link>
    <description>Recent content in Posts on Evangeline M Reynolds</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2018</copyright>
    <lastBuildDate>Sun, 01 Jan 2017 00:00:00 +0100</lastBuildDate>
    
	<atom:link href="/post/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Federalist Papers</title>
      <link>/post/federalist-papers/</link>
      <pubDate>Sat, 16 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/federalist-papers/</guid>
      <description>Every couple of weeks I like to explore data that’s brand new to me. I anticipate a one-hour, one-off project. Usually this turns out to be a beautiful lie, and the projects chew up much more time. Still, this enticing time-line is pulling me into new projects from time to time.
Earlier this week, I heard about the dispute of authorship of some of the Federalist papers.
&amp;quot;Hamilton wrote the other 51!</description>
    </item>
    
    <item>
      <title>Geometric interpretation of Covariance</title>
      <link>/post/geometric-covariance/</link>
      <pubDate>Thu, 14 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/geometric-covariance/</guid>
      <description>So. Visualizing the correlation coefficient.
But actually covariance first. Correlation coefficient presents some challenges. (Many dimensions!!)
First the Covariance:
\(cov(x,y) = \frac{\sum_1^n (x_i-\overline{x})(y_i-\overline{y})}{n-1}\)
library(tidyverse) ## ── Attaching packages ──────── ## ✔ ggplot2 2.2.1.9000 ✔ purrr 0.2.5 ## ✔ tibble 1.4.2 ✔ dplyr 0.7.5 ## ✔ tidyr 0.8.1 ✔ stringr 1.3.1 ## ✔ readr 1.1.1 ✔ forcats 0.3.0 ## ── Conflicts ───────────────── ## ✖ dplyr::filter() masks stats::filter() ## ✖ dplyr::lag() masks stats::lag() x &amp;lt;- rnorm(30) y &amp;lt;- -x + rnorm(30, sd = .</description>
    </item>
    
    <item>
      <title>Eat near the Big Ben?  That will cost you...</title>
      <link>/post/eat-near-the-big-ben-that-will-cost-you/</link>
      <pubDate>Tue, 12 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/eat-near-the-big-ben-that-will-cost-you/</guid>
      <description>What’s the cost of eating near an iconic location? We all might suspect eating in a fun location is pricier. I used the menu and restaurant location data that #MakeoverMonday “assigned” one week last December to demonstrate this among London Wetherspoon Pubs.
#MakeoverMonday is a fun data visualization initiative; most participants use Tableau as their preferred visualization tool. But I’ve used R and ggplot() and the organizers and participants have been very welcoming.</description>
    </item>
    
    <item>
      <title>What’s the IGO dataset?</title>
      <link>/post/what-s-the-igo-dataset/</link>
      <pubDate>Fri, 08 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/what-s-the-igo-dataset/</guid>
      <description>The International Organization v2.3 dataset is a rich resource for scholars of international relations. Tracking the existence of international organizations and country memberships in them, the data’s various version have been cited over 450 times. Version 2.3 covers the time period 1815 to 2005, and records information about 529 IGOs and membership information for over two million country-igo-year observations. Before 1965, coding was performed only every five years; thereafter information about IGOs and membership is available on an annual basis.</description>
    </item>
    
    <item>
      <title>What’s the IGO dataset?</title>
      <link>/post/what-s-the-igo-dataset/</link>
      <pubDate>Fri, 08 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/what-s-the-igo-dataset/</guid>
      <description>The International Organization v2.3 dataset is a rich resource for scholars of international relations. Tracking the existence of international organizations and country memberships in them, the data&amp;rsquo;s various version have been cited over 450 times. Version 2.3 covers the time period 1815 to 2005, and records information about 529 IGOs and membership information for over two million country-igo-year observations. Before 1965, coding was performed only every five years; thereafter information about IGOs and membership is available on an annual basis.</description>
    </item>
    
    <item>
      <title>Central Limit Theorem Demonstration</title>
      <link>/post/central-limit-theorem/</link>
      <pubDate>Thu, 07 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/central-limit-theorem/</guid>
      <description>Sir Francis Galton described the Central Limit Theorem in this way:
I know of scarcely anything so apt to impress the imagination as the wonderful form of cosmic order expressed by the “Law of Frequency of Error”
Why is Sir Francis Galton so excited? Because the Central Limit Theorem (CLT) gives us such clear expectations for random sample means! (A random sample mean is simply the mean of a value for a random sample from a population of interest.</description>
    </item>
    
    <item>
      <title>From N to Standard Deviation: Visualizing Univariate Statistics</title>
      <link>/post/univariate-statistics-visualizing-variance/</link>
      <pubDate>Wed, 06 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/univariate-statistics-visualizing-variance/</guid>
      <description>This post goes back and forth between computing statistics for a single variable and visualizing these values. I’m using a subset of the gapminder dataset — European countries in 2007, and focusing on the Life Expectancy variable.
This post is developed from lecture slides for my great students in my intro to data science and statistics course at TU Dresden.
I’m most excited about the walk-through of the variance calculation. In preparing to lecture on univariate stats, I came across a nice visualization of variance explained but couldn’t find a visualization just focused on explaining the variance itself.</description>
    </item>
    
    <item>
      <title>Winter Games and Athlete Ages</title>
      <link>/post/winter-games-and-athlete-ages/</link>
      <pubDate>Sat, 02 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/winter-games-and-athlete-ages/</guid>
      <description>In February, I made a plot on athletes ages at the Winter Olympics for the data visualization initiative #MakeoverMonday. The initiative is mostly Tableau enthusiasts practicing data visualization techniques. I use it to practice visualization with R. It also serves as a forum for chatting about what works and what doesn’t work in communication data visually which can be good food for thought. My viz had this description:
Winter games individual medalists are most likely to be athletes in their twenties.</description>
    </item>
    
    <item>
      <title>Layered Presentation of Graphics with &#43;aes() in ggplot2</title>
      <link>/post/layered-presentation-of-graphics-with-aes-in-ggplot2/</link>
      <pubDate>Mon, 21 May 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/layered-presentation-of-graphics-with-aes-in-ggplot2/</guid>
      <description>Here is the post is about how to implement a layered presentation of a graphics. Matthew Blackwell tweeted about the concept earlier this year, which seemed to reasonated with a lot of folks - to the tune of &amp;gt; 1500 likes! Practical, pedegogical stuff tends to get people excited. True for me too.
My best tip on how to give better quantitative presentations is to (a) use more plots and (b) build up your plots on multiple overlays, as in:</description>
    </item>
    
    <item>
      <title>First Blogdown blogpost</title>
      <link>/post/first-blogdown-post/</link>
      <pubDate>Sat, 19 May 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/first-blogdown-post/</guid>
      <description>This is my first post just a test of blogdown.
It seems to be working fine also with this R code.
x = 5 x^2 ## [1] 25 And this Python code:
print(&amp;quot;hello&amp;quot; + &amp;quot;there&amp;quot;) ## hellothere Let’s check out how a graph looks too:
library(ggplot2) ggplot(mtcars) + aes(mpg, disp, col = as.factor(cyl)) + geom_point() Looks good. I’m very satisfied. Hooray for blogdown!</description>
    </item>
    
    <item>
      <title>Academic Hugo and Blogdown</title>
      <link>/post/getting-started/</link>
      <pubDate>Wed, 20 Apr 2016 00:00:00 +0200</pubDate>
      
      <guid>/post/getting-started/</guid>
      <description>About Academic Hugo from the creator:
Academic is a framework to help you create a beautiful website quickly. Perfect for personal sites, blogs, or business/project sites. Check out the latest demo of what you&amp;rsquo;ll get in less than 10 minutes. Then head on over to the Quick Start guide or take a look at the Release Notes.

About Blogdown:
https://bookdown.org/yihui/blogdown/
https://alison.rbind.io/post/up-and-running-with-blogdown/ (very helpful step-by-step instructions)</description>
    </item>
    
  </channel>
</rss>