
# ðŸ‘‹ Thanks for dropping by!

Stuff I do:

- [x] Descriptive Statistics, Statistical Modeling, Machine Learning
  (with emphasis on viz)
- [x] Visualization (ggplot2, plotnine, Tableau), Table Generation
  (tidypivot, gt, greattables, flextable)
- [x] Dashboarding (Experience with Shiny, powerBI, Tableau)
- [x] Research Reporting (Scholarly, Institutional; Rmarkdown, Quarto)
- [x] Workflow/Pipeline Management (tidyverse, base R, SQL)
- [x] Research Software Engineering (experienced R package maintainer,
  \> 5 years)
- [x] Statistical Consulting
  <!-- - [x]  Technical Communication (oral and written) -->
- [x] Data Science Education (excellence in class, and world wide)
- [x] Version Control, Collaborative Workflows, Git, Github, Github
  Actions
- [x] Productive, Professional, and Friendly Working Relationships with
  Collaborators with diverse technical and subject area backgrounds
- [x] Tidyverse Fluency (dplyr, ggplot2, tidyr, purrr, etc)
- [x] R Packaging Expertise (workflow tools, documentation, testing)
- [x] Visualization Frameworks (spatial, network, grammar of graphics,
  ggdims)
- [x] Contributor to popular open source libraries (ggplot2, plotnine)
- [x] Author, maintainer of popular libraries (flipbookr, ggcirclepack)
- [x] Experience with CRAN submission process and maintanance
  (flipbookr, tidytitanic)

<!-- Bachelor's degree in software development or a directly related field from an accredited institution. -->

<!-- Three (3) years of software development, software or system engineering, bioinformatics, or directly related IT professional experience. -->

<!-- Two (2) years of experience in data analysis using R with common analysis utilities (Tidyverse, dplyr, etc.). -->

<!-- Two (2) years of experience with manipulating large datasets to transform, profile, sanitize, explore, analyze, and present information in a reproducible way. -->

<!-- Two (2) years of experience with version control, preferably with Git -->

<!-- Experience developing and deploying reusable and robust R packages, including familiarity with testing frameworks (testthat) and documentation generation (roxygen2). -->

<!-- A combination of education and related technical/military/paraprofessional experience may be substituted for a bachelorâ€™s degree on a year for year basis. An advanced degree (Masters or Doctorate) may be substituted for experience on a year for year basis if the degree is in a field of study directly related to the work assignment. -->

<!-- - [x]  Reproducible computing environments, containerization -->

I work on tools that make data analytics more fluid and intuitive and on
tools which expose this fluidity and elegance. These tools also allow us
to better record â€˜conversationsâ€™ with data and workflows.

<!-- ```{r} -->

<!-- ``` -->

<!-- exported functions: last_plot_data, data_unfilter, data_slice_sample, data_refilter, aes_dims, data_var_split, data_include, data_filter, data_arrange, dims_unpack, data_replace, last_plot_wipe_last, last_plot_wipe, data_slice_max, intercept, dims0, aes_from_data, data_slice -->

<!-- tidypivot - -->

<!-- exported functions: `getNamespaceExports("tidypivot")` -->

<!-- ggdims - -->

<!-- exported functions: StatTsneGroup, theme_ggdims, compute_pca_rows, dims, compute_tsne_group_label, GeomPointFill, geom_tsne_label, StatPcaRows, geom_pca, StatTsne, geom_umap0, geom_tsne_label0, geom_pca0, compute_umap, vars_unpack, geom_tsne, data_vars_unpack, geom_tsne0, compute_tsne, dims_listed, geom_umap, dims_expand, StatUmap -->

<!-- ggregions - write_stamp_region_locale, write_geom_region_locale, write_stamp_region_text_locale, write_geom_region_text_locale, compute_panel_regions -->

<!-- statexpress - proto_update, qstat_group, qproto_update, qstat, qstat_panel, qstat_layer, qlayer -->

<!-- Record conversations: -->

<!-- ggprop.test - geom_normal_prop_null_sds, geom_support, geom_prop, geom_normal_prop_null, geom_stack, stamp_prop, geom_prop_label, stamp_eq_norm_prop, geom_stack_label, stamp_prop_label -->

<!-- Expose this fluidity and elegance: -->

<!-- flipbookr - embed_flipbook, text_reveal, %>%, create_base_pipe_code, return_chunk_code, chunk_reveal, reveal_live -->

<!-- ggram - -->

<!-- Education: -->

<!-- easy-geom-recipes -->

<!-- easy-geom-recipes-python -->

<!-- easy.geom.recipes.package -->

<!-- knitrExpress -->

My popular projects include
[flipbookr](https://github.com/EvaMaeRey/flipbookr) (on CRAN and
maintained since 2020, with \>20000 downloads and used across
disciplines) and ggplot2 extensions like
[ggcalendar](https://evamaerey.github.io/ggcalendar/),
[ggcirclepack](https://github.com/EvaMaeRey/ggcirclepack) and others.

Professionally, Iâ€™ve worked in higher education and government where my
work involved analytics, teaching, and policy implementation.

Iâ€™m interested in lightening cognative load, first, when interpreting
data visualizations and, second, when writing and reading code used to
build data visualizations. I believe intuitiveness of plot composition
tools (coding and gui interfaces) often translates to more effective
visualization. With logical, easy-to-use tools, weâ€™re better positioned
to build compelling, easy-to-interpret visualizations, rather than
stopping at â€˜good enoughâ€™. For these reasons, Iâ€™m a big fan of the
elegant and intuitive grammar of graphics visualization frameworks.

My technical expertise is in ggplot2 and my current focus is on
extension and supporting extenders. I co-founded and organize the
[ggplot2 extenders
club](https://ggplot2-extenders.github.io/ggplot-extension-club/)â€¦

, have created [â€˜easy geom
recipesâ€™](https://evamaerey.github.io/easy-geom-recipes/), am writing
[ggplot2 extension
cookbook](https://github.com/EvaMaeRey/ggplot2-extension-cookbook), and
developing [â€˜expressâ€™ methodologies for
extension](https://github.com/EvaMaeRey/ggexpress) (why shouldnâ€™t
everyone be using extension and why shouldnâ€™t we be using them even on
an *ad hoc* basis?).

Iâ€™ve studied some of these new educational materials via [survey
response and focus
groups](https://evamaerey.github.io/easy-geom-recipes/survey_results_summary.html).
For more on the motivation for these efforts, see [â€˜everyday ggplot2
extensionâ€™](https://evamaerey.github.io/everyday_ggplot2_extension/).

Iâ€™m interested in the transformational effects that access to tailored,
principled data visualization tools can have on analytic and teaching
spaces. I work on greater accessibility for analysts, research, and
students to craft tool suited to their particular data challenges.

Previously, I had a greater focus on illuminating the grammar of *base*
ggplot2, creating materials like [a ggplot2 grammar
guide](https://evamaerey.github.io/ggplot2_grammar_guide/about) and [the
ggplot2
flipbook](https://evamaerey.github.io/ggplot_flipbook/ggplot_flipbook_xaringan.html#1).

I am also especially interested in entry points to R package writing,
working on resources like a [â€™companion
guide](https://evamaerey.github.io/package_in_20_minutes/package_in_20_minutes)
to to Jim Hesterâ€™s talk how to write and R package in 20 minutesâ€™ (2000)
I have also looked comparatively at literate package writing tools of
[{fusen}](https://thinkr-open.github.io/fusen/),
[{litr}](https://jacobbien.github.io/litr-project/), and my own
â€˜readme-to-packageâ€™ approach, including via an coordinating a virtual
meeting with the authors at RLadies Denver, [March 2024
meeting](meetup.com/rladies-denver/events/299879858/?eventOrigin=group_past_events).
The [note package (2025)](https://github.com/musician-tools/note) uses
my [{knitrExtra}](https://github.com/EvaMaeRey/knitrExtra) package to
create the note package (a lightly rewritten version of what Jim Hester
presented) from within a README.

<!-- Some projects that I'm especially excited about at the moment are: -->
